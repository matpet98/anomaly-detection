{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for general handling of numerical data\n",
    "import pandas as pd # for dataframes\n",
    "import librosa\n",
    "import librosa.display as dis\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import csv\n",
    "import os\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import metrics\n",
    "from scipy import signal \n",
    "np.random.seed(10)\n",
    "from sklearn.covariance import EllipticEnvelope \n",
    "from sklearn.metrics import average_precision_score\n",
    "outliers_fraction = 0.25\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from window_slider import Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates header of csv file with number filename, cwt and stft \n",
    "def create_header_with_label():\n",
    "    header = 'filename'\n",
    "    for i in range(1, 21):\n",
    "        header += f' cwt{i}'\n",
    "    for i in range(1, 11):\n",
    "        header += f' stft{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates csv file with header from create_header_() and a given name.csv\n",
    "def create_csv(name,header):\n",
    "    file = open(name, 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracte features from each file and write into csv file\n",
    "def write_data_2_csv_from_wav(path,name):\n",
    "    header = create_header_with_label()\n",
    "    create_csv(name,header)\n",
    "    # extracte cwt and stft \n",
    "    for filename in os.listdir(f'{path}'):\n",
    "        if not filename.startswith('.') and os.path.isfile(os.path.join(path, filename)):\n",
    "            file = f'{path}{filename}'\n",
    "            y, sr = librosa.load(file)\n",
    "            # extract stft matrix from section\n",
    "            stftmatr = np.abs(librosa.stft(y, n_fft = 19))\n",
    "            stftmatr_square = np.square(np.square(stftmatr))\n",
    "            # extract cwt matrix from section\n",
    "            widths = np.arange(1, 21)\n",
    "            cwtmatr = signal.cwt(y, signal.ricker, widths)\n",
    "            cwtmatr_square = np.square(np.square(cwtmatr))\n",
    "             # write data into csv file\n",
    "            to_append = f'{filename}'\n",
    "            for c in cwtmatr_square:\n",
    "                to_append += f' {np.mean(c)}'\n",
    "            for s in stftmatr_square:\n",
    "                to_append += f' {np.mean(s)}'\n",
    "            # label abnormal data with 1 and normal data with 0\n",
    "            if filename.startswith('ab'):\n",
    "                to_append += f' {1}' \n",
    "            else:\n",
    "                to_append += f' {0}' \n",
    "            file = open(name, 'a', newline='')\n",
    "            with file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implements sliding window\n",
    "# extracte features from each file and write into csv file\n",
    "def write_data_2_csv_from_wav_slider(path,name):\n",
    "    header = create_header_with_label()\n",
    "    create_csv(name,header)\n",
    "    for filename in os.listdir(f'{path}'):\n",
    "        if not filename.startswith('.') and os.path.isfile(os.path.join(path, filename)):\n",
    "            file = f'{path}{filename}'\n",
    "            y, sr = librosa.load(file)\n",
    "            size_overlap = round(sr/2)\n",
    "            size_window = round(sr)\n",
    "            slider = Slider(size_window,size_overlap)\n",
    "            slider.fit(y)\n",
    "            sections = []\n",
    "            while True:\n",
    "                window_data = slider.slide()\n",
    "                sections.append(window_data)\n",
    "                if slider.reached_end_of_list(): break\n",
    "            i = 0\n",
    "            for sec in sections:\n",
    "                y = sections[i]\n",
    "                \n",
    "                stftmatr = np.abs(librosa.stft(y, n_fft = 19))\n",
    "                stftmatr_square = np.square(np.square(stftmatr))\n",
    "                widths = np.arange(1, 21)\n",
    "                cwtmatr = signal.cwt(y, signal.ricker, widths)\n",
    "                cwtmatr_square = np.square(np.square(cwtmatr))\n",
    "                to_append = f'{filename}'\n",
    "                for c in cwtmatr_square:\n",
    "                    to_append += f' {np.mean(c)}'\n",
    "                    \n",
    "                for s in stftmatr_square:\n",
    "                    to_append += f' {np.mean(s)}'\n",
    "                if filename.startswith('ab'):\n",
    "                    to_append += f' {1}' \n",
    "                else:\n",
    "                    to_append += f' {0}' \n",
    "                file = open(name, 'a', newline='')\n",
    "                with file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(to_append.split())\n",
    "                i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads csv file\n",
    "def load_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    compare = df #df zum vergleichen für AUC\n",
    "    \n",
    "    data = df.drop(['filename' , 'label'],axis=1)\n",
    "    return data ,compare \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesses data\n",
    "def preprocess_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    processed_data = scaler.fit_transform(np.array(data, dtype = float))\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one class support vector machine implementation with sklearn + auc score\n",
    "def train_OCSVM_AUC(data):\n",
    "    model =  OneClassSVM(nu=0.95 * outliers_fraction, gamma=0.1) #nu=0.95 * outliers_fraction  + 0.05\n",
    "    model.fit(data)\n",
    "    compare['anomalyOCSVM'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyOCSVM'] = compare['anomalyOCSVM'].map( {1: 0, -1: 1} )\n",
    "    print(compare['anomalyOCSVM'].value_counts())\n",
    "    cmp = compare.drop(['filename'],axis=1)\n",
    "    y = cmp['label'].to_numpy()\n",
    "    pred = cmp['anomalyOCSVM'].to_numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest implementation with sklearn + auc score\n",
    "def train_IF_AUC(data):\n",
    "    rng = np.random.RandomState(10)\n",
    "    model = IsolationForest(contamination = outliers_fraction, max_samples=100, random_state=rng)\n",
    "    model.fit(data)\n",
    "    compare['anomalyIF'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyIF'] = compare['anomalyIF'].map( {1: 0, -1: 1} )\n",
    "    print(compare['anomalyIF'].value_counts())\n",
    "    cmp = compare.drop(['filename'],axis=1)\n",
    "    y = cmp['label'].to_numpy()\n",
    "    pred = cmp['anomalyIF'].to_numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means implementation with sklearn + auc score\n",
    "def getDistanceByPoint(data, model):\n",
    "    distance = []\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.append(np.linalg.norm(Xa-Xb))\n",
    "    return pd.Series(distance, index=data.index)\n",
    "def train_kmeans_AUC(data):\n",
    "    pca = PCA(n_components=2)\n",
    "    data = pca.fit_transform(data)\n",
    "    # standardize these 2 new features\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(np_scaled)\n",
    "    n_cluster = range(1, 50)\n",
    "    kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]\n",
    "    scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "    \n",
    "    compare['cluster'] = kmeans[1].predict(data)\n",
    "    compare['principal_feature1'] = data[0]\n",
    "    compare['principal_feature2'] = data[1]\n",
    "    print(compare['cluster'].value_counts())\n",
    "    \n",
    "    distance = getDistanceByPoint(data, kmeans[0])\n",
    "    number_of_outliers = int(outliers_fraction*len(distance))\n",
    "    threshold = distance.nlargest(number_of_outliers).min()\n",
    "    # anomaly21 contain the anomaly result of method 2.1 Cluster (0:normal, 1:anomaly) \n",
    "    compare['anomalyKmeans'] = (distance >= threshold).astype(int)\n",
    "    \n",
    "    y = compare['label'].to_numpy()\n",
    "    pred = compare['anomalyKmeans'].to_numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    print(metrics.auc(fpr, tpr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elliptic envelope implementation with sklearn + auc score\n",
    "def train_EE_AUC(data):\n",
    "    model = EllipticEnvelope(random_state=0, contamination = outliers_fraction, support_fraction = 1.5)\n",
    "    model.fit(data)\n",
    "    compare['anomalyEE'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyEE'] = compare['anomalyEE'].map( {1: 0, -1: 1} )\n",
    "    print(compare['anomalyEE'].value_counts())\n",
    "    y = compare['label'].to_numpy()\n",
    "    pred = compare['anomalyEE'].to_numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    print(metrics.auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________\n",
      "____OCSVM____\n",
      "0    9500\n",
      "1    2960\n",
      "Name: anomalyOCSVM, dtype: int64\n",
      "0.6875\n",
      "_____________\n",
      "______IF_____\n",
      "0    9345\n",
      "1    3115\n",
      "Name: anomalyIF, dtype: int64\n",
      "0.6556647940074907\n",
      "_____________\n",
      "______EE_____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiaspetry/Library/Python/3.7/lib/python/site-packages/sklearn/covariance/_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9345\n",
      "1    3115\n",
      "Name: anomalyEE, dtype: int64\n",
      "0.72874531835206\n",
      "_____________\n",
      "____KMeans___\n",
      "0    9747\n",
      "1    2713\n",
      "Name: cluster, dtype: int64\n",
      "0.6166666666666666\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "# extracte features an run ml algorithms\n",
    "header = create_header_with_label()\n",
    "name = create_csv(\"data_id_06_slide.csv\",header)\n",
    "write_data_2_csv_from_wav_slider(\"Dataset/id_06/\",name)\n",
    "data, compare = load_csv(\"data_id_06_slide.csv\")\n",
    "processed_data = preprocess_data(data)\n",
    "print(\"_____________\")\n",
    "print(\"____OCSVM____\")\n",
    "train_OCSVM_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"______IF_____\")\n",
    "train_IF_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"______EE_____\")\n",
    "train_EE_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"____KMeans___\")\n",
    "train_kmeans_AUC(processed_data)\n",
    "print(\"_____________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________\n",
      "____OCSVM____\n",
      "0    1016\n",
      "1     319\n",
      "Name: anomalyOCSVM, dtype: int64\n",
      "0.6924157303370787\n",
      "_____________\n",
      "______IF_____\n",
      "0    1001\n",
      "1     334\n",
      "Name: anomalyIF, dtype: int64\n",
      "0.7673220973782773\n",
      "_____________\n",
      "______EE_____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiaspetry/Library/Python/3.7/lib/python/site-packages/sklearn/covariance/_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1001\n",
      "1     334\n",
      "Name: anomalyEE, dtype: int64\n",
      "0.7556179775280898\n",
      "_____________\n",
      "____KMeans___\n",
      "1    690\n",
      "0    645\n",
      "Name: cluster, dtype: int64\n",
      "0.8122659176029963\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "# load file with extracted features and run ml algorithms \n",
    "data, compare = load_csv(\"Extracted Data/MIMII/data_id_02_20_10.csv\")\n",
    "processed_data = preprocess_data(data)\n",
    "print(\"_____________\")\n",
    "print(\"____OCSVM____\")\n",
    "train_OCSVM_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"______IF_____\")\n",
    "train_IF_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"______EE_____\")\n",
    "train_EE_AUC(processed_data)\n",
    "print(\"_____________\")\n",
    "print(\"____KMeans___\")\n",
    "train_kmeans_AUC(processed_data)\n",
    "print(\"_____________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extrated features for overview\n",
    "anomalies = compare.drop([\"cwt1\",\"cwt2\",\"cwt3\",\"cwt4\",\"cwt5\",\"cwt6\",\"cwt7\",\"cwt8\",\"cwt9\",\"cwt10\",\"cwt11\",\"cwt12\",\"cwt13\",\"cwt14\",\"cwt15\",\"cwt16\",\"cwt17\",\"cwt18\",\"cwt19\",\"cwt20\",\"stft1\",\"stft2\",\"stft3\",\"stft4\",\"stft5\",\"stft6\",\"stft7\",\"stft8\",\"stft9\",\"stft10\",\"cluster\",\"principal_feature1\",\"principal_feature2\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specific anomolies \n",
    "find_file = anomalies[anomalies.anomalyIF == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>anomalyOCSVM</th>\n",
       "      <th>anomalyIF</th>\n",
       "      <th>anomalyEE</th>\n",
       "      <th>anomalyKmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ab_000000058.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ab_000000058.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ab_000000058.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ab_000000058.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>ab_000000058.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28475</th>\n",
       "      <td>ab_000000096.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28476</th>\n",
       "      <td>ab_000000096.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28477</th>\n",
       "      <td>ab_000000096.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>ab_000000096.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28479</th>\n",
       "      <td>ab_000000096.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  label  anomalyOCSVM  anomalyIF  anomalyEE  \\\n",
       "140    ab_000000058.wav      1             1          1          1   \n",
       "141    ab_000000058.wav      1             1          1          1   \n",
       "142    ab_000000058.wav      1             1          1          1   \n",
       "143    ab_000000058.wav      1             1          1          1   \n",
       "144    ab_000000058.wav      1             1          1          1   \n",
       "...                 ...    ...           ...        ...        ...   \n",
       "28475  ab_000000096.wav      1             1          1          1   \n",
       "28476  ab_000000096.wav      1             1          1          1   \n",
       "28477  ab_000000096.wav      1             1          1          1   \n",
       "28478  ab_000000096.wav      1             1          1          1   \n",
       "28479  ab_000000096.wav      1             1          1          1   \n",
       "\n",
       "       anomalyKmeans  \n",
       "140                1  \n",
       "141                1  \n",
       "142                1  \n",
       "143                1  \n",
       "144                1  \n",
       "...              ...  \n",
       "28475              1  \n",
       "28476              1  \n",
       "28477              1  \n",
       "28478              1  \n",
       "28479              0  \n",
       "\n",
       "[7120 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows list sections where anomolies are fund \n",
    "find_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
