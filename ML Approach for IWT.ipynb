{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for general handling of numerical data\n",
    "import pandas as pd # for dataframes\n",
    "import librosa\n",
    "import librosa.display as dis\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import csv\n",
    "import os\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import metrics\n",
    "from scipy import signal \n",
    "from sklearn.covariance import EllipticEnvelope \n",
    "from window_slider import Slider\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readQASS(filepath, fs):\n",
    "    \"\"\"\n",
    "    Read QASS data from binary file format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : STR\n",
    "        is the full path to sur file.\n",
    "    fs : sampling frequency of the measurement\n",
    " \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df:  a pandas dataframe with time and amplitude.\n",
    "    \"\"\"\n",
    "    time_interval = 1/fs\n",
    "    \n",
    "    data = np.fromfile(filepath, dtype='int16')\n",
    "    time = np.arange(0, len(data)*time_interval, time_interval)\n",
    "    df = pd.DataFrame({'time': time, 'amplitude':data})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates header of csv file with number of section start/end time, cwt and stft \n",
    "def create_header_():\n",
    "    header = 'nr start end'\n",
    "    for i in range(1, 21):\n",
    "        header += f' cwt{i}'\n",
    "    for i in range(1, 11):\n",
    "        header += f' stft{i}'\n",
    "    header = header.split()\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates csv file with header from create_header_() and a given name.csv\n",
    "def create_csv(header,name):\n",
    "    file = open(name, 'w', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split .bin file into 32ms sections\n",
    "# extracte features from each section and write into csv file\n",
    "def write_data_2_csv_from_bin(file,name):\n",
    "    i = 0\n",
    "    sr = 1562500\n",
    "    measurement_data = readQASS(file, sr)\n",
    "    amplitude_data = measurement_data['amplitude'].astype(float)\n",
    "    # cut last part so length of section can be the same length\n",
    "    data_length = amplitude_data.size - (amplitude_data.size%50000)\n",
    "    # find the the number of sections for np.array_split function\n",
    "    n = data_length/((1562500/1000) * 32)\n",
    "    # splits data into n arrays of size (1562500/1000) * 32)\n",
    "    sections = np.array_split(amplitude_data[0:data_length], n)\n",
    "    # start/end time for localizing anomoly\n",
    "    start = 0\n",
    "    end = 32\n",
    "    # extracte cwt and stft from sections\n",
    "    for section in sections:\n",
    "        y = sections[i].to_numpy()\n",
    "        # extract stft matrix from section\n",
    "        widths = np.arange(1, 21)\n",
    "        stftmatr = np.abs(librosa.stft(y, n_fft = 19))\n",
    "        stftmatr_square = np.square(np.square(stftmatr))\n",
    "        \n",
    "        # extract cwt matrix from section\n",
    "        cwtmatr = signal.cwt(y, signal.ricker, widths)\n",
    "        cwtmatr_square = np.square(np.square(cwtmatr))\n",
    "        \n",
    "        # write data into csv file\n",
    "        to_append = f'{i}'  \n",
    "        to_append += f' {start} {end}' \n",
    "        for c in cwtmatr_square:\n",
    "            to_append += f' {np.mean(c)}'\n",
    "        for s in stftmatr_square:\n",
    "            to_append += f' {np.mean(s)}'    \n",
    "        file = open(name, 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "        # increase start/end time\n",
    "        end = end + 32 \n",
    "        start = start + 32\n",
    "        i = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implements sliding window on data \n",
    "# writes data into csv file\n",
    "def write_data_2_csv_from_bin_sliding_window(file,name):\n",
    "    i = 0\n",
    "    sr = 1562500\n",
    "    measurement_data = readQASS(file, sr)\n",
    "    amplitude_data = measurement_data['amplitude'].astype(float)\n",
    "    y = amplitude_data.to_numpy()\n",
    "    \n",
    "    # calcultes window and overlap size of 32ms and 16ms\n",
    "    size_window = int((1562500/1000) * 32)\n",
    "    size_overlap = round(((1562500/1000) * 16))\n",
    "    \n",
    "    # uses window_slider libary to implement sliding window\n",
    "    slider = Slider(size_window,size_overlap)\n",
    "    slider.fit(y)\n",
    "    sections = []\n",
    "    while True:\n",
    "        window_data = slider.slide()\n",
    "        # do your stuff\n",
    "        sections.append(window_data)\n",
    "        if slider.reached_end_of_list(): break\n",
    "    \n",
    "    # start/end time for localizing anomoly \n",
    "    start = 0\n",
    "    end = 32 \n",
    "    \n",
    "    # extracte cwt and stft from sections\n",
    "    for sec in sections:\n",
    "        y = sections[i]\n",
    "        widths = np.arange(1, 21)\n",
    "        stftmatr = np.abs(librosa.stft(y, n_fft = 19))\n",
    "        stftmatr_square = np.square(np.square(stftmatr))\n",
    "        cwtmatr = signal.cwt(y, signal.ricker, widths)\n",
    "        cwtmatr_square = np.square(np.square(cwtmatr))\n",
    "        to_append = f'{i}'  \n",
    "        \n",
    "        to_append += f' {start} {end}' \n",
    "        for c in cwtmatr_square:\n",
    "            to_append += f' {np.mean(c)}'\n",
    "        for s in stftmatr_square:\n",
    "            to_append += f' {np.mean(s)}'\n",
    "            \n",
    "            \n",
    "        file = open(name, 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())\n",
    "        i = i+1\n",
    "        \n",
    "        # increase start/end time\n",
    "        start = start + 16\n",
    "        end = end + 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads csv file\n",
    "def load_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    compare = df #df zum vergleichen für AUC\n",
    "    \n",
    "    data = df.drop(['start', \"end\", \"nr\"],axis=1)\n",
    "\n",
    "    return data ,compare \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesses data\n",
    "def preprocess_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    processed_data = scaler.fit_transform(np.array(data, dtype = float))\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest implementation with sklearn\n",
    "def train_IF_(data):\n",
    "    rng = np.random.RandomState(10)\n",
    "    model = IsolationForest(contamination = outliers_fraction, random_state=rng)\n",
    "    model.fit(data)\n",
    "    compare['anomalyIF'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyIF'] = compare['anomalyIF'].map( {1: 0, -1: 1} )\n",
    "    \n",
    "    print(compare['anomalyIF'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elliptic envelope implementation with sklearn\n",
    "def train_EE(data):\n",
    "    model = EllipticEnvelope(random_state=1,contamination = outliers_fraction, support_fraction= 1)\n",
    "    \n",
    "    model.fit(data)\n",
    "    compare['anomalyEE'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyEE'] = compare['anomalyEE'].map( {1: 0, -1: 1} )\n",
    "    print(compare['anomalyEE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means implementation with sklearn\n",
    "def getDistanceByPoint(data, model):\n",
    "    distance = []\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.loc[i])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.append(np.linalg.norm(Xa-Xb))\n",
    "    return pd.Series(distance, index=data.index)\n",
    "def train_kmeans(data):\n",
    "    pca = PCA(n_components=2)\n",
    "    data = pca.fit_transform(data)\n",
    "    # standardize these 2 new features\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(np_scaled)\n",
    "    n_cluster = range(1, 20)\n",
    "    kmeans = [KMeans(n_clusters=i).fit(data) for i in n_cluster]\n",
    "    scores = [kmeans[i].score(data) for i in range(len(kmeans))]\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.plot(n_cluster, scores)\n",
    "    #plt.show()\n",
    "    compare['cluster'] = kmeans[1].predict(data)\n",
    "    compare['principal_feature1'] = data[0]\n",
    "    compare['principal_feature2'] = data[1]\n",
    "    distance = getDistanceByPoint(data, kmeans[1])\n",
    "    number_of_outliers = int(outliers_fraction*len(distance))\n",
    "    threshold = distance.nlargest(number_of_outliers).min()\n",
    "    # anomaly21 contain the anomaly result of method 2.1 Cluster (0:normal, 1:anomaly) \n",
    "    compare['anomalyKmeans'] = (distance >= threshold).astype(int)\n",
    "    print(compare['anomalyKmeans'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one class support vector machine implementation with sklearn \n",
    "def train_OCSVM_(data): \n",
    "    model =  OneClassSVM(nu=0.95 * outliers_fraction, gamma=0.1) #nu=0.95 * outliers_fraction  + 0.05\n",
    "    model.fit(data)\n",
    "    compare['anomalyOCSVM'] = pd.Series(model.predict(data))\n",
    "    compare['anomalyOCSVM'] = compare['anomalyOCSVM'].map( {1: 0, -1: 1} )\n",
    "    print(compare['anomalyOCSVM'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extracte features from .bin file \n",
    "# writes into csv file and runs ml algorithms\n",
    "\n",
    "# outlier fractions \n",
    "outliers_fraction = 0.1\n",
    "header = create_header_()\n",
    "root = \"Acoustic Emission/Parametervariation/\" #root of dataset folder\n",
    "# create_csv(header,name of csv)\n",
    "name = create_csv(header,\"Fe_KleineKörner_vc150_fa7,5_SIG_Raw.csv\")\n",
    "path = root + \"Fe_GroßeKörner_vc050_fa02,5_SIG_Raw.bin\" \n",
    "\n",
    "# write_data_2_csv_from_bin(path,name) for dividing data into 32ms sections\n",
    "write_data_2_csv_from_bin(path,name)\n",
    "# write_data_2_csv_from_bin_sliding_window(file,name) for sliding window \n",
    "#write_data_2_csv_from_bin_sliding_window(file,name)\n",
    "data ,compare = load_csv(name)\n",
    "processed_data = preprocess_data(data)\n",
    "print(\"_______IF_________\")\n",
    "train_IF_(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"______OCSVM_______\")\n",
    "train_OCSVM_(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"_______EE_________\")\n",
    "train_EE(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"______K-Means_____\")\n",
    "train_kmeans(processed_data)\n",
    "print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrate features for each file in folder\n",
    "outliers_fraction = 0.1\n",
    "path = \"Acoustic Emission/Parametervariation/\"\n",
    "for filename in os.listdir(f'{path}'):\n",
    "    if not filename.startswith('.') and os.path.isfile(os.path.join(path, filename)):\n",
    "        file = f'{path}{filename}'\n",
    "        name = filename.split(\".\")[0]+\".csv\"\n",
    "        header = create_header_()\n",
    "        name = create_csv(header,name)\n",
    "        write_data_2_csv_from_bin(file,name)\n",
    "        #write_data_2_csv_from_bin_sliding_window(file,name)\n",
    "        data ,compare = load_csv(name)\n",
    "        processed_data = preprocess_data(data)\n",
    "        print(\"..................\")\n",
    "        print(filename)\n",
    "        print(\"_______IF_________\")\n",
    "        train_IF_(processed_data)\n",
    "        print(\"__________________\")\n",
    "        print(\"______OCSVM_______\")\n",
    "        train_OCSVM_(processed_data)\n",
    "        print(\"__________________\")\n",
    "        print(\"_______EE_________\")\n",
    "        train_EE(processed_data)\n",
    "        print(\"__________________\")\n",
    "        print(\"______K-Means_____\")\n",
    "        train_kmeans(processed_data)\n",
    "        print(\"__________________\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______IF_________\n",
      "0    459\n",
      "1     51\n",
      "Name: anomalyIF, dtype: int64\n",
      "__________________\n",
      "______OCSVM_______\n",
      "0    460\n",
      "1     50\n",
      "Name: anomalyOCSVM, dtype: int64\n",
      "__________________\n",
      "_______EE_________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthiaspetry/Library/Python/3.7/lib/python/site-packages/sklearn/covariance/_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    459\n",
      "1     51\n",
      "Name: anomalyEE, dtype: int64\n",
      "__________________\n",
      "______K-Means_____\n",
      "0    459\n",
      "1     51\n",
      "Name: anomalyKmeans, dtype: int64\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "# load an already created csv file\n",
    "outliers_fraction = 0.1\n",
    "\n",
    "name = \"Extracted Data/IWT/Parametervariation/Sliding Window/Fe_GroßeKörner_vc150_fa15_SIG_Rawslide_dataset.csv\"\n",
    "data ,compare = load_csv(name)\n",
    "processed_data = preprocess_data(data)\n",
    "print(\"_______IF_________\")\n",
    "train_IF_(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"______OCSVM_______\")\n",
    "train_OCSVM_(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"_______EE_________\")\n",
    "train_EE(processed_data)\n",
    "print(\"__________________\")\n",
    "print(\"______K-Means_____\")\n",
    "train_kmeans(processed_data)\n",
    "print(\"__________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extrated features for overview\n",
    "anomaly = compare.drop([\"cwt1\",\"cwt2\",\"cwt3\",\"cwt4\",\"cwt5\",\"cwt6\",\"cwt7\",\"cwt8\",\"cwt9\",\"cwt10\",\"cwt11\",\"cwt12\",\"cwt13\",\"cwt14\",\"cwt15\",\"cwt16\",\"cwt17\",\"cwt18\",\"cwt19\",\"cwt20\",\"stft1\",\"stft2\",\"stft3\",\"stft4\",\"stft5\",\"stft6\",\"stft7\",\"stft8\",\"stft9\",\"stft10\",\"cluster\",\"principal_feature1\",\"principal_feature2\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract specific anomolies \n",
    "find_anomaly = anomaly[anomaly.anomalyIF == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>anomalyIF</th>\n",
       "      <th>anomalyOCSVM</th>\n",
       "      <th>anomalyEE</th>\n",
       "      <th>anomalyKmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>3040</td>\n",
       "      <td>3072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>3136</td>\n",
       "      <td>3168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>3152</td>\n",
       "      <td>3184</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>3184</td>\n",
       "      <td>3216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>3200</td>\n",
       "      <td>3232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>3296</td>\n",
       "      <td>3328</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>214</td>\n",
       "      <td>3424</td>\n",
       "      <td>3456</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>3600</td>\n",
       "      <td>3632</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>3616</td>\n",
       "      <td>3648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>3632</td>\n",
       "      <td>3664</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>3648</td>\n",
       "      <td>3680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>3696</td>\n",
       "      <td>3728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>4112</td>\n",
       "      <td>4144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>4352</td>\n",
       "      <td>4384</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>4368</td>\n",
       "      <td>4400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>4448</td>\n",
       "      <td>4480</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>279</td>\n",
       "      <td>4464</td>\n",
       "      <td>4496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>280</td>\n",
       "      <td>4480</td>\n",
       "      <td>4512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>4496</td>\n",
       "      <td>4528</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>4640</td>\n",
       "      <td>4672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>4656</td>\n",
       "      <td>4688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>4688</td>\n",
       "      <td>4720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>4704</td>\n",
       "      <td>4736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>4912</td>\n",
       "      <td>4944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>4928</td>\n",
       "      <td>4960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>4944</td>\n",
       "      <td>4976</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>4960</td>\n",
       "      <td>4992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>4976</td>\n",
       "      <td>5008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>315</td>\n",
       "      <td>5040</td>\n",
       "      <td>5072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>316</td>\n",
       "      <td>5056</td>\n",
       "      <td>5088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>317</td>\n",
       "      <td>5072</td>\n",
       "      <td>5104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>5152</td>\n",
       "      <td>5184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>5168</td>\n",
       "      <td>5200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>5184</td>\n",
       "      <td>5216</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>5200</td>\n",
       "      <td>5232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>326</td>\n",
       "      <td>5216</td>\n",
       "      <td>5248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>5232</td>\n",
       "      <td>5264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>328</td>\n",
       "      <td>5248</td>\n",
       "      <td>5280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>5264</td>\n",
       "      <td>5296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>5376</td>\n",
       "      <td>5408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>5392</td>\n",
       "      <td>5424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>5472</td>\n",
       "      <td>5504</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>5568</td>\n",
       "      <td>5600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>5712</td>\n",
       "      <td>5744</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>5728</td>\n",
       "      <td>5760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>5840</td>\n",
       "      <td>5872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>6528</td>\n",
       "      <td>6560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>6928</td>\n",
       "      <td>6960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>434</td>\n",
       "      <td>6944</td>\n",
       "      <td>6976</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>436</td>\n",
       "      <td>6976</td>\n",
       "      <td>7008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>6992</td>\n",
       "      <td>7024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nr  start   end  anomalyIF  anomalyOCSVM  anomalyEE  anomalyKmeans\n",
       "190  190   3040  3072          1             0          0              0\n",
       "196  196   3136  3168          1             1          0              0\n",
       "197  197   3152  3184          1             0          0              0\n",
       "199  199   3184  3216          1             1          0              0\n",
       "200  200   3200  3232          1             1          0              1\n",
       "206  206   3296  3328          1             1          0              1\n",
       "214  214   3424  3456          1             1          0              1\n",
       "225  225   3600  3632          1             1          1              1\n",
       "226  226   3616  3648          1             1          0              1\n",
       "227  227   3632  3664          1             1          1              1\n",
       "228  228   3648  3680          1             1          1              1\n",
       "231  231   3696  3728          1             1          1              1\n",
       "257  257   4112  4144          1             1          1              1\n",
       "272  272   4352  4384          1             0          1              1\n",
       "273  273   4368  4400          1             1          1              1\n",
       "278  278   4448  4480          1             0          1              1\n",
       "279  279   4464  4496          1             0          0              1\n",
       "280  280   4480  4512          1             0          1              1\n",
       "281  281   4496  4528          1             0          0              1\n",
       "290  290   4640  4672          1             0          1              1\n",
       "291  291   4656  4688          1             1          1              1\n",
       "293  293   4688  4720          1             1          0              1\n",
       "294  294   4704  4736          1             1          0              1\n",
       "307  307   4912  4944          1             0          1              1\n",
       "308  308   4928  4960          1             1          0              1\n",
       "309  309   4944  4976          1             1          0              1\n",
       "310  310   4960  4992          1             1          0              1\n",
       "311  311   4976  5008          1             1          1              1\n",
       "315  315   5040  5072          1             1          0              1\n",
       "316  316   5056  5088          1             1          1              1\n",
       "317  317   5072  5104          1             0          1              1\n",
       "322  322   5152  5184          1             1          0              1\n",
       "323  323   5168  5200          1             1          0              0\n",
       "324  324   5184  5216          1             0          1              1\n",
       "325  325   5200  5232          1             0          1              1\n",
       "326  326   5216  5248          1             0          1              1\n",
       "327  327   5232  5264          1             1          1              1\n",
       "328  328   5248  5280          1             1          1              1\n",
       "329  329   5264  5296          1             0          1              1\n",
       "336  336   5376  5408          1             0          1              1\n",
       "337  337   5392  5424          1             0          1              0\n",
       "342  342   5472  5504          1             0          1              1\n",
       "348  348   5568  5600          1             1          1              1\n",
       "357  357   5712  5744          1             0          1              1\n",
       "358  358   5728  5760          1             0          1              0\n",
       "365  365   5840  5872          1             1          0              0\n",
       "408  408   6528  6560          1             1          0              1\n",
       "433  433   6928  6960          1             1          0              0\n",
       "434  434   6944  6976          1             0          0              0\n",
       "436  436   6976  7008          1             0          0              0\n",
       "437  437   6992  7024          1             1          0              1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows list sections where anomolies are fund \n",
    "find_anomaly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
